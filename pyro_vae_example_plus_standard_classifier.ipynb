{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.datasets as dset\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.contrib.examples.util  # patches torchvision\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert pyro.__version__.startswith('1.3.0')\n",
    "pyro.enable_validation(True)\n",
    "pyro.distributions.enable_validation(False)\n",
    "pyro.set_rng_seed(0)\n",
    "# Enable smoke test - run the notebook cells on CI.\n",
    "#smoke_test = 'CI' in os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_data_loaders(batch_size=128, use_cuda=False):\n",
    "    root = './data'\n",
    "    download = True\n",
    "    trans = transforms.ToTensor()\n",
    "    train_set = dset.MNIST(root=root, train=True, transform=trans,\n",
    "                           download=download)\n",
    "    test_set = dset.MNIST(root=root, train=False, transform=trans)\n",
    "\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': use_cuda}\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_set,\n",
    "        batch_size=batch_size, shuffle=True, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_set,\n",
    "        batch_size=batch_size, shuffle=False, **kwargs)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        # setup the two linear transformations used\n",
    "        self.fc1 = nn.Linear(z_dim, hidden_dim)\n",
    "        self.fc21 = nn.Linear(hidden_dim, 784)\n",
    "        # setup the non-linearities\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, z):\n",
    "        # define the forward computation on the latent z\n",
    "        # first compute the hidden units\n",
    "        hidden = self.softplus(self.fc1(z))\n",
    "        # return the parameter for the output Bernoulli\n",
    "        # each is of size batch_size x 784\n",
    "        loc_img = self.sigmoid(self.fc21(hidden))\n",
    "        return loc_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        # setup the three linear transformations used\n",
    "        self.fc1 = nn.Linear(784, hidden_dim)\n",
    "        self.fc21 = nn.Linear(hidden_dim, z_dim)\n",
    "        self.fc22 = nn.Linear(hidden_dim, z_dim)\n",
    "        # setup the non-linearities\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # define the forward computation on the image x\n",
    "        # first shape the mini-batch to have pixels in the rightmost dimension\n",
    "        x = x.reshape(-1, 784)\n",
    "        # then compute the hidden units\n",
    "        hidden = self.softplus(self.fc1(x))\n",
    "        # then return a mean vector and a (positive) square root covariance\n",
    "        # each of size batch_size x z_dim\n",
    "        z_loc = self.fc21(hidden)\n",
    "        z_scale = torch.exp(self.fc22(hidden))\n",
    "        return z_loc, z_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model p(x|z)p(z)\n",
    "def model(self, x):\n",
    "    # register PyTorch module `decoder` with Pyro\n",
    "    pyro.module(\"decoder\", self.decoder)\n",
    "    with pyro.plate(\"data\", x.shape[0]):\n",
    "        # setup hyperparameters for prior p(z)\n",
    "        z_loc = x.new_zeros(torch.Size((x.shape[0], self.z_dim)))\n",
    "        # z loc torch.Size([256, 50])\n",
    "        z_scale = x.new_ones(torch.Size((x.shape[0], self.z_dim)))\n",
    "        # sample from prior (value will be sampled by guide when computing the ELBO)\n",
    "        z = pyro.sample(\"latent\", dist.Normal(z_loc, z_scale).to_event(1))\n",
    "        # we sample a Z from a (0, I) normal distribution\n",
    "        # then we pass it though a nn\n",
    "        # mu = nn(z)\n",
    "        # then this mu is used in another dist\n",
    "        # p(x|z) where z is samples\n",
    "        # then we sample an x from this\n",
    "        # the idea is, this nn function learns a distribution\n",
    "        # that is, what would it be like to sample z from P(z|X)\n",
    "        # \n",
    "        # z shape torch.Size([256, 50])\n",
    "        # decode the latent code z\n",
    "        loc_img = self.decoder.forward(z)\n",
    "        #loc img torch.Size([256, 784])\n",
    "        # score against actual images\n",
    "        # bern shape Independent(Bernoulli(probs: torch.Size([256, 784])), 1)\n",
    "        # 784 is the batch size\n",
    "        # 256 is the image size\n",
    "        pyro.sample(\"obs\", dist.Bernoulli(loc_img).to_event(1), obs=x.reshape(-1, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the guide (i.e. variational distribution) q(z|x)\n",
    "def guide(self, x):\n",
    "    # register PyTorch module `encoder` with Pyro\n",
    "    pyro.module(\"encoder\", self.encoder)\n",
    "    with pyro.plate(\"data\", x.shape[0]):\n",
    "        # use the encoder to get the parameters used to define q(z|x)\n",
    "        z_loc, z_scale = self.encoder.forward(x)\n",
    "        # p(z,b) = q(b)mult(i=1 to i=N)q(zi|f(xi))\n",
    "        \n",
    "        # given an image, we output a distribution for z\n",
    "        # then we sample a z. because the guide always gives the\n",
    "        # approximate posterior, the variational inference\n",
    "        # sample the latent code z\n",
    "        pyro.sample(\"latent\", dist.Normal(z_loc, z_scale).to_event(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    # by default our latent space is 50-dimensional\n",
    "    # and we use 400 hidden units\n",
    "    def __init__(self, z_dim=50, hidden_dim=400, use_cuda=False):\n",
    "        super().__init__()\n",
    "        # create the encoder and decoder networks\n",
    "        self.encoder = Encoder(z_dim, hidden_dim)\n",
    "        self.decoder = Decoder(z_dim, hidden_dim)\n",
    "\n",
    "        if use_cuda:\n",
    "            # calling cuda() here will put all the parameters of\n",
    "            # the encoder and decoder networks into gpu memory\n",
    "            self.cuda()\n",
    "        self.use_cuda = use_cuda\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "    # define the model p(x|z)p(z)\n",
    "    \n",
    "    \n",
    "    def model(self, x):\n",
    "        # register PyTorch module `decoder` with Pyro\n",
    "        pyro.module(\"decoder\", self.decoder)\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            # setup hyperparameters for prior p(z)\n",
    "            z_loc = x.new_zeros(torch.Size((x.shape[0], self.z_dim)))\n",
    "            z_scale = x.new_ones(torch.Size((x.shape[0], self.z_dim)))\n",
    "            # sample from prior (value will be sampled by guide when computing the ELBO)\n",
    "            z = pyro.sample(\"latent\", dist.Normal(z_loc, z_scale).to_event(1))\n",
    "            # decode the latent code z\n",
    "            loc_img = self.decoder.forward(z)\n",
    "            # score against actual images\n",
    "            # decoder is where the image goes \n",
    "            pyro.sample(\"obs\", dist.Bernoulli(loc_img).to_event(1), obs=x.reshape(-1, 784))\n",
    "\n",
    "    # define the guide (i.e. variational distribution) q(z|x)\n",
    "    def guide(self, x):\n",
    "        # register PyTorch module `encoder` with Pyro\n",
    "        pyro.module(\"encoder\", self.encoder)\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            # use the encoder to get the parameters used to define q(z|x)\n",
    "            z_loc, z_scale = self.encoder.forward(x)\n",
    "            # sample the latent code z\n",
    "            pyro.sample(\"latent\", dist.Normal(z_loc, z_scale).to_event(1))\n",
    "\n",
    "    # define a helper function for reconstructing images\n",
    "    def reconstruct_img(self, x):\n",
    "        # encode image x\n",
    "        z_loc, z_scale = self.encoder(x)\n",
    "        # sample in latent space\n",
    "        z = dist.Normal(z_loc, z_scale).sample()\n",
    "        # decode the image (note we don't sample in image space)\n",
    "        loc_img = self.decoder(z)\n",
    "        return loc_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE()\n",
    "\n",
    "optimizer = Adam({\"lr\": 1.0e-3})\n",
    "\n",
    "svi = SVI(vae.model, vae.guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "def train(svi, train_loader, use_cuda=False):\n",
    "    # initialize loss accumulator\n",
    "    epoch_loss = 0.\n",
    "    # do a training epoch over each mini-batch x returned\n",
    "    # by the data loader\n",
    "    for x, _ in train_loader:\n",
    "        # if on GPU put mini-batch into CUDA memory\n",
    "        if use_cuda:\n",
    "            x = x.cuda()\n",
    "        # do ELBO gradient and accumulate loss\n",
    "        epoch_loss += svi.step(x)\n",
    "\n",
    "    # return epoch loss\n",
    "    normalizer_train = len(train_loader.dataset)\n",
    "    total_epoch_loss_train = epoch_loss / normalizer_train\n",
    "    return total_epoch_loss_train\n",
    "\n",
    "def evaluate(svi, test_loader, use_cuda=False):\n",
    "    # initialize loss accumulator\n",
    "    test_loss = 0.\n",
    "    # compute the loss over the entire test set\n",
    "    for x, _ in test_loader:\n",
    "        # if on GPU put mini-batch into CUDA memory\n",
    "        if use_cuda:\n",
    "            x = x.cuda()\n",
    "        # compute ELBO estimate and accumulate loss\n",
    "        test_loss += svi.evaluate_loss(x)\n",
    "    normalizer_test = len(test_loader.dataset)\n",
    "    total_epoch_loss_test = test_loss / normalizer_test\n",
    "    return total_epoch_loss_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 000]  average training loss: 191.0216\n",
      "[epoch 000] average test loss: 156.0872\n",
      "[epoch 001]  average training loss: 146.8141\n",
      "[epoch 002]  average training loss: 133.2540\n",
      "[epoch 003]  average training loss: 124.6775\n",
      "[epoch 004]  average training loss: 119.5152\n",
      "[epoch 005]  average training loss: 116.1240\n",
      "[epoch 005] average test loss: 113.7908\n",
      "[epoch 006]  average training loss: 113.7285\n",
      "[epoch 007]  average training loss: 112.0445\n",
      "[epoch 008]  average training loss: 110.7292\n",
      "[epoch 009]  average training loss: 109.7455\n",
      "[epoch 010]  average training loss: 108.9070\n",
      "[epoch 010] average test loss: 107.7720\n",
      "[epoch 011]  average training loss: 108.2513\n",
      "[epoch 012]  average training loss: 107.6953\n",
      "[epoch 013]  average training loss: 107.2849\n",
      "[epoch 014]  average training loss: 106.8870\n",
      "[epoch 015]  average training loss: 106.4983\n",
      "[epoch 015] average test loss: 105.9786\n",
      "[epoch 016]  average training loss: 106.1872\n",
      "[epoch 017]  average training loss: 105.9363\n",
      "[epoch 018]  average training loss: 105.7087\n",
      "[epoch 019]  average training loss: 105.4600\n",
      "[epoch 020]  average training loss: 105.2648\n",
      "[epoch 020] average test loss: 104.7753\n",
      "[epoch 021]  average training loss: 105.0442\n",
      "[epoch 022]  average training loss: 104.9031\n",
      "[epoch 023]  average training loss: 104.7304\n",
      "[epoch 024]  average training loss: 104.6027\n",
      "[epoch 025]  average training loss: 104.4586\n",
      "[epoch 025] average test loss: 104.2971\n",
      "[epoch 026]  average training loss: 104.3756\n",
      "[epoch 027]  average training loss: 104.2278\n",
      "[epoch 028]  average training loss: 104.1049\n",
      "[epoch 029]  average training loss: 104.0565\n",
      "[epoch 030]  average training loss: 103.8851\n",
      "[epoch 030] average test loss: 103.5858\n",
      "[epoch 031]  average training loss: 103.7705\n",
      "[epoch 032]  average training loss: 103.7331\n",
      "[epoch 033]  average training loss: 103.6272\n",
      "[epoch 034]  average training loss: 103.5645\n",
      "[epoch 035]  average training loss: 103.4693\n",
      "[epoch 035] average test loss: 103.1316\n",
      "[epoch 036]  average training loss: 103.3898\n",
      "[epoch 037]  average training loss: 103.3199\n",
      "[epoch 038]  average training loss: 103.2840\n",
      "[epoch 039]  average training loss: 103.1866\n",
      "[epoch 040]  average training loss: 103.1108\n",
      "[epoch 040] average test loss: 103.0911\n",
      "[epoch 041]  average training loss: 103.0730\n",
      "[epoch 042]  average training loss: 103.0086\n",
      "[epoch 043]  average training loss: 102.9338\n",
      "[epoch 044]  average training loss: 102.8886\n",
      "[epoch 045]  average training loss: 102.8416\n",
      "[epoch 045] average test loss: 102.8022\n",
      "[epoch 046]  average training loss: 102.7832\n",
      "[epoch 047]  average training loss: 102.7389\n",
      "[epoch 048]  average training loss: 102.6800\n",
      "[epoch 049]  average training loss: 102.6738\n",
      "[epoch 050]  average training loss: 102.5855\n",
      "[epoch 050] average test loss: 102.5790\n",
      "[epoch 051]  average training loss: 102.5615\n",
      "[epoch 052]  average training loss: 102.4934\n",
      "[epoch 053]  average training loss: 102.4610\n",
      "[epoch 054]  average training loss: 102.4274\n",
      "[epoch 055]  average training loss: 102.3712\n",
      "[epoch 055] average test loss: 102.3923\n",
      "[epoch 056]  average training loss: 102.3328\n",
      "[epoch 057]  average training loss: 102.2912\n",
      "[epoch 058]  average training loss: 102.1891\n",
      "[epoch 059]  average training loss: 102.2194\n",
      "[epoch 060]  average training loss: 102.1762\n",
      "[epoch 060] average test loss: 102.1223\n",
      "[epoch 061]  average training loss: 102.1585\n",
      "[epoch 062]  average training loss: 102.0887\n",
      "[epoch 063]  average training loss: 102.0703\n",
      "[epoch 064]  average training loss: 102.0091\n",
      "[epoch 065]  average training loss: 101.9924\n",
      "[epoch 065] average test loss: 102.0361\n",
      "[epoch 066]  average training loss: 101.9461\n",
      "[epoch 067]  average training loss: 101.8985\n",
      "[epoch 068]  average training loss: 101.8809\n",
      "[epoch 069]  average training loss: 101.8587\n",
      "[epoch 070]  average training loss: 101.8102\n",
      "[epoch 070] average test loss: 102.1124\n",
      "[epoch 071]  average training loss: 101.7739\n",
      "[epoch 072]  average training loss: 101.7548\n",
      "[epoch 073]  average training loss: 101.7252\n",
      "[epoch 074]  average training loss: 101.7424\n",
      "[epoch 075]  average training loss: 101.6693\n",
      "[epoch 075] average test loss: 101.8703\n",
      "[epoch 076]  average training loss: 101.6238\n",
      "[epoch 077]  average training loss: 101.5941\n",
      "[epoch 078]  average training loss: 101.5562\n",
      "[epoch 079]  average training loss: 101.5380\n",
      "[epoch 080]  average training loss: 101.4967\n",
      "[epoch 080] average test loss: 101.6312\n",
      "[epoch 081]  average training loss: 101.4572\n",
      "[epoch 082]  average training loss: 101.4549\n",
      "[epoch 083]  average training loss: 101.3729\n",
      "[epoch 084]  average training loss: 101.3880\n",
      "[epoch 085]  average training loss: 101.3953\n",
      "[epoch 085] average test loss: 101.5520\n",
      "[epoch 086]  average training loss: 101.3212\n",
      "[epoch 087]  average training loss: 101.3289\n",
      "[epoch 088]  average training loss: 101.3108\n",
      "[epoch 089]  average training loss: 101.2534\n",
      "[epoch 090]  average training loss: 101.2607\n",
      "[epoch 090] average test loss: 101.2997\n",
      "[epoch 091]  average training loss: 101.2435\n",
      "[epoch 092]  average training loss: 101.1965\n",
      "[epoch 093]  average training loss: 101.1350\n",
      "[epoch 094]  average training loss: 101.1215\n",
      "[epoch 095]  average training loss: 101.0969\n",
      "[epoch 095] average test loss: 101.2543\n",
      "[epoch 096]  average training loss: 101.1045\n",
      "[epoch 097]  average training loss: 101.0621\n",
      "[epoch 098]  average training loss: 101.0410\n",
      "[epoch 099]  average training loss: 101.0019\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 1.0e-3\n",
    "USE_CUDA = False\n",
    "smoke_test = False\n",
    "\n",
    "# Run only for a single iteration for testing\n",
    "NUM_EPOCHS = 1 if smoke_test else 100\n",
    "TEST_FREQUENCY = 5\n",
    "train_loader, test_loader = setup_data_loaders(batch_size=256, use_cuda=USE_CUDA)\n",
    "\n",
    "# clear param store\n",
    "pyro.clear_param_store()\n",
    "\n",
    "# setup the VAE\n",
    "vae = VAE(use_cuda=USE_CUDA)\n",
    "\n",
    "# setup the optimizer\n",
    "adam_args = {\"lr\": LEARNING_RATE}\n",
    "optimizer = Adam(adam_args)\n",
    "\n",
    "# setup the inference algorithm\n",
    "svi = SVI(vae.model, vae.guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "train_elbo = []\n",
    "test_elbo = []\n",
    "# training loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    total_epoch_loss_train = train(svi, train_loader, use_cuda=USE_CUDA)\n",
    "    train_elbo.append(-total_epoch_loss_train)\n",
    "    print(\"[epoch %03d]  average training loss: %.4f\" % (epoch, total_epoch_loss_train))\n",
    "\n",
    "    if epoch % TEST_FREQUENCY == 0:\n",
    "        # report test diagnostics\n",
    "        total_epoch_loss_test = evaluate(svi, test_loader, use_cuda=USE_CUDA)\n",
    "        test_elbo.append(-total_epoch_loss_test)\n",
    "        print(\"[epoch %03d] average test loss: %.4f\" % (epoch, total_epoch_loss_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write classifier\n",
    "# inputs a latent vector, outputs a class\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, z_dim, hidden):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(z_dim*2, hidden)\n",
    "        self.fc2 = nn.Linear(hidden, hidden)\n",
    "        self.fc3 = nn.Linear(hidden, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        hidden1 = self.fc1(x)\n",
    "        hidden2 = self.fc2(hidden1)\n",
    "        hidden3 = self.fc3(hidden2)\n",
    "        return nn.functional.log_softmax(hidden3, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_is = next(iter(train_loader))\n",
    "# this is a single batch, i.e. it has 256 elements in it\n",
    "# it is a list, the first element is the images,\n",
    "# second element is the labels\n",
    "single_image = next_is[0][0]\n",
    "single_label = next_is[1][0]\n",
    "# single image of size \n",
    "# first element is of len 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100])\n"
     ]
    }
   ],
   "source": [
    "# grab a vae_encoder and get z for a particular x\n",
    "z_loc, z_scale = vae.encoder(single_image)\n",
    "\n",
    "third_tensor = torch.cat((z_loc, z_scale), 1)\n",
    "print(third_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3209564685821533\n",
      "0.1437\n",
      "2.2574594020843506\n",
      "0.2087\n",
      "2.205500364303589\n",
      "0.3128\n",
      "2.1685173511505127\n",
      "0.3845\n",
      "2.1243441104888916\n",
      "0.4691\n",
      "2.072411060333252\n",
      "0.5629\n",
      "2.045624256134033\n",
      "0.6215\n",
      "1.9650495052337646\n",
      "0.6607\n",
      "1.90550696849823\n",
      "0.6806\n",
      "1.868747591972351\n",
      "0.704\n",
      "1.8410223722457886\n",
      "0.7256\n",
      "1.6797776222229004\n",
      "0.7574\n",
      "1.669885516166687\n",
      "0.7642\n",
      "1.53873872756958\n",
      "0.7806\n",
      "1.5082895755767822\n",
      "0.7944\n",
      "1.4565718173980713\n",
      "0.801\n",
      "1.3914974927902222\n",
      "0.8089\n",
      "1.2749780416488647\n",
      "0.8179\n",
      "1.2252825498580933\n",
      "0.8229\n",
      "1.178971529006958\n",
      "0.8305\n",
      "1.0609190464019775\n",
      "0.835\n",
      "1.0536940097808838\n",
      "0.84\n"
     ]
    }
   ],
   "source": [
    "# train classifier classifies z, and categories\n",
    "# test classifier.\n",
    "import torch.optim as optim\n",
    "\n",
    "def test(encoder, classifier, test_loader):\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        z_loc, z_scale = vae.encoder(data)\n",
    "        combined_z = torch.cat((z_loc, z_scale), 1)\n",
    "    \n",
    "        output = classifier.forward(combined_z)\n",
    "        pred = output.argmax(dim=1)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    return correct / len(test_loader.dataset)\n",
    "\n",
    "def train_classifier(train_loader, test_loader, use_cuda=False):\n",
    "    # initialize loss accumulator\n",
    "    running_loss = 0.\n",
    "    # do a training epoch over each mini-batch x returned\n",
    "    # by the data loader\n",
    "    classifier=Classifier(50,200)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(classifier.parameters(), lr=0.001, momentum=0.9)\n",
    "    for epoch in range(2):\n",
    "        i = 0\n",
    "        for x, y in train_loader:\n",
    "            # if on GPU put mini-batch into CUDA memory\n",
    "            if use_cuda:\n",
    "                x = x.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            z_loc, z_scale = vae.encoder(x)\n",
    "            combined_z = torch.cat((z_loc, z_scale), 1)\n",
    "    \n",
    "            \n",
    "            outputs = classifier.forward(combined_z)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            i+=1\n",
    "            if i % 20 == 0:    # print every 2000 mini-batches\n",
    "                print(loss.item())\n",
    "                accuracy = test(vae.encoder, classifier, test_loader)\n",
    "                print(\"test accuracy\", accuracy)\n",
    "            \n",
    "        i+=1\n",
    "train_classifier(train_loader, test_loader)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
